{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x563c290>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input and tokenize some raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 ['we', 'are', 'about', 'to', 'study', 'the', 'idea', 'of', 'a', 'computational']\n"
     ]
    }
   ],
   "source": [
    "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\".lower()\n",
    "\n",
    "token_text = word_tokenize(raw_text)\n",
    "\n",
    "print(len(token_text), token_text[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing (word to index, index to word, freq. dictionary, subsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of vocabulary:  46\n"
     ]
    }
   ],
   "source": [
    "# set of vocab items\n",
    "vocab = set(token_text)\n",
    "vocab_size = len(vocab)\n",
    "print(\"size of vocabulary: \", vocab_size)\n",
    "\n",
    "# dictionaries mapping from word to index and vica versa\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "ix_to_word = {i: word for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random number used for subsampling: 0.54287\n",
      "discarded (ie. high-frequency) words:\n",
      "0.84834 we\n",
      "0.78552 about\n",
      "0.78552 study\n",
      "0.78552 idea\n",
      "0.89276 a\n",
      "0.84834 process\n",
      "0.84834 computational\n",
      "0.84834 are\n",
      "0.78552 beings\n",
      "0.78552 inhabit\n",
      "0.91244 .\n",
      "0.78552 they\n",
      "0.84834 ,\n",
      "0.78552 manipulate\n",
      "0.84834 abstract\n",
      "0.84834 called\n",
      "0.91244 .\n",
      "0.78552 evolution\n",
      "0.89276 a\n",
      "0.78552 is\n",
      "0.78552 by\n",
      "0.78552 pattern\n",
      "0.78552 rules\n",
      "0.89276 a\n",
      "0.91244 .\n",
      "0.78552 create\n",
      "0.84834 to\n",
      "0.87617 processes\n",
      "0.78552 in\n",
      "0.84834 ,\n",
      "0.78552 conjure\n",
      "0.78552 spirits\n",
      "0.89276 the\n",
      "0.78552 with\n",
      "0.78552 spells\n",
      "length of tokenized text after subsampling:  35\n"
     ]
    }
   ],
   "source": [
    "# global variables for subsampling\n",
    "THRESHOLD = 0.001\n",
    "RAND = np.random.sample()\n",
    "\n",
    "def word_freqs(text, subsampling=True):\n",
    "    \"\"\"\n",
    "    creates a word frequency dictionary of tokenized text, optionally subsamples from tokenized text\n",
    "    \n",
    "    args:\n",
    "        text (list): list of words from tokenized text\n",
    "        subsampling (bool): whether to use subsampling of frequent words (see [1])\n",
    "    returns:\n",
    "        (subsampled) tokenized text\n",
    "        freq_dict (dict): frequency dictionary of tokenized text\n",
    "    \"\"\"\n",
    "    freq_dict = {}\n",
    "    for word in text:\n",
    "        if word not in freq_dict:\n",
    "            freq_dict[word] = 0\n",
    "        freq_dict[word] += 1.0\n",
    "        \n",
    "    # subsampling: if a given word has a high(er than some random number) relative frequency, then discard it\n",
    "    if subsampling:\n",
    "        print(\"random number used for subsampling:\", round(RAND, 5))\n",
    "        print(\"discarded (ie. high-frequency) words:\")\n",
    "        for i, word in enumerate(text):\n",
    "            prob_discard = 1 - np.sqrt(THRESHOLD * len(freq_dict.keys()) / freq_dict[word])   # probability of word being discarded\n",
    "            if (RAND <= prob_discard):\n",
    "                print(round(prob_discard, 5), word)\n",
    "                del [text[i]]\n",
    "                i -= 1\n",
    "        print(\"length of tokenized text after subsampling: \", len(text))\n",
    "    return text, freq_dict\n",
    "\n",
    "token_text, freq_dict = word_freqs(token_text)\n",
    "    \n",
    "\n",
    "# distribution of frequencies (list)\n",
    "freq_distr = [freq_dict[ix_to_word[i]] for i in range(len(freq_dict))]\n",
    "#print(freq_distr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data processing for Skip-Gram and CBOW, with negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipgram data count: 134 \n",
      "skipgram data sample: [([21], 26), ([21], 38), ([26], 21), ([26], 38), ([26], 23), ([38], 26), ([38], 21), ([38], 23), ([38], 25), ([23], 38)]\n",
      "cbow data count: 35 \n",
      "cbow data sample: [([26, 38], 21), ([21, 38, 23], 26), ([26, 21, 23, 25], 38), ([38, 26, 25, 40], 23), ([23, 38, 40, 27], 25), ([25, 23, 27, 41], 40), ([40, 25, 41, 15], 27), ([27, 40, 15, 2], 41), ([41, 27, 2, 39], 15), ([15, 41, 39, 34], 2)]\n",
      "weights for each word after negative sampling tensor([[ 8.],\n",
      "        [ 7.],\n",
      "        [ 7.],\n",
      "        [ 5.],\n",
      "        [ 6.],\n",
      "        [16.],\n",
      "        [ 9.],\n",
      "        [ 8.],\n",
      "        [ 8.],\n",
      "        [10.],\n",
      "        [14.],\n",
      "        [ 8.],\n",
      "        [ 3.],\n",
      "        [18.],\n",
      "        [12.],\n",
      "        [ 6.],\n",
      "        [10.],\n",
      "        [ 9.],\n",
      "        [ 8.],\n",
      "        [11.],\n",
      "        [ 8.],\n",
      "        [ 6.],\n",
      "        [ 9.],\n",
      "        [26.],\n",
      "        [ 8.],\n",
      "        [18.],\n",
      "        [11.],\n",
      "        [23.],\n",
      "        [ 9.],\n",
      "        [ 6.],\n",
      "        [ 5.],\n",
      "        [11.],\n",
      "        [ 7.],\n",
      "        [15.],\n",
      "        [ 8.],\n",
      "        [11.],\n",
      "        [11.],\n",
      "        [ 4.],\n",
      "        [20.],\n",
      "        [10.],\n",
      "        [33.],\n",
      "        [13.],\n",
      "        [19.],\n",
      "        [14.],\n",
      "        [ 8.],\n",
      "        [10.]])\n"
     ]
    }
   ],
   "source": [
    "# global variables for data processing\n",
    "CONTEXT_SIZE = 2\n",
    "NUM_NEG_SAMPLES = 10\n",
    "MODEL = \"skipgram\" #or \"cbow\"\n",
    "        \n",
    "def create_dataset(text, word_to_ix, context_size=CONTEXT_SIZE, model=MODEL):\n",
    "    \"\"\"\n",
    "    creates dataset in accordance with the Skip-gram and CBOW models\n",
    "    \n",
    "    args:\n",
    "        text (list): list of words from tokenized text\n",
    "        word_to_ix (dict): word to index dictionary\n",
    "        context_size (int): size of window to one side\n",
    "        model (str): either \"skipgram\" or \"cbow\"\n",
    "        \n",
    "    returns:\n",
    "        data (list of tuples): dataset according to Skip-gram or CBOW principles\n",
    "            Skip-gram: ([center word index], context word index)\n",
    "            CBOW: ([indices of context words], center word index)\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for ix, word in enumerate(text):\n",
    "        # forward and backward counters and indices\n",
    "        back_counter, for_counter = 0, 0\n",
    "        back_ix, for_ix = ix - 1, ix + 1\n",
    "        if model == \"skipgram\":\n",
    "            # while we're within the context window, append data w/ positive examples\n",
    "            while 0 <= back_ix and back_counter < context_size:\n",
    "                data.append(([word_to_ix[word]], word_to_ix[text[back_ix]])) # ([center word ix], context word ix)\n",
    "                back_ix -= 1\n",
    "                back_counter += 1\n",
    "            while for_ix < len(text) and for_counter < context_size:\n",
    "                data.append(([word_to_ix[word]], word_to_ix[text[for_ix]]))\n",
    "                for_ix += 1\n",
    "                for_counter += 1\n",
    "\n",
    "        elif model == \"cbow\":\n",
    "            # define context comprising words that are surrounding the center word\n",
    "            # then append it\n",
    "            context = []\n",
    "            while 0 <= back_ix and back_counter < context_size:\n",
    "                context.append(word_to_ix[text[back_ix]])\n",
    "                back_ix -= 1\n",
    "                back_counter += 1\n",
    "            while for_ix < len(text) and for_counter < context_size:\n",
    "                context.append(word_to_ix[text[for_ix]])\n",
    "                for_ix += 1\n",
    "                for_counter += 1\n",
    "            # append data with ([context], center word ix):\n",
    "            data.append((context, word_to_ix[word]))\n",
    "    return data\n",
    "\n",
    "def neg_sampling(ix_to_word, freq_distr, num_neg_samples=NUM_NEG_SAMPLES):\n",
    "    ## weighted unigram frequency\n",
    "    # raised to 3/4th power and normalized\n",
    "    freq_distr_norm = F.normalize(torch.Tensor(freq_distr).pow(0.75), dim=0)\n",
    "\n",
    "    # initialize an all-one vec of size |V|×1 ~> weights \n",
    "    #NB. at the beginning, each word is a positive, so gets a weight of 1\n",
    "    weights = torch.ones(len(freq_distr), 1)\n",
    "    \n",
    "    # for each positive word, generate num_neg_samples as many negative samples\n",
    "    for _ in range(len(freq_distr)):\n",
    "        for _ in range(num_neg_samples):\n",
    "            neg_ix = torch.multinomial(freq_distr_norm, 1)[0] #Q. what if the negative sample happens to be a positive (ie. existing data)?\n",
    "            weights[neg_ix] += 1\n",
    "    return weights\n",
    "\n",
    "\n",
    "data_skipgram = create_dataset(token_text, word_to_ix, context_size=CONTEXT_SIZE, model=\"skipgram\")\n",
    "data_cbow = create_dataset(token_text, word_to_ix, context_size=CONTEXT_SIZE, model=\"cbow\")\n",
    "weights = neg_sampling(ix_to_word, freq_distr, num_neg_samples=NUM_NEG_SAMPLES)\n",
    "print(\"skipgram data count:\", len(data_skipgram), \"\\nskipgram data sample:\", data_skipgram[:10])\n",
    "print(\"cbow data count:\", len(data_cbow), \"\\ncbow data sample:\", data_cbow[:10])\n",
    "print(\"weights for each word after negative sampling\", weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 50\n",
    "\n",
    "class SkipGram(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(SkipGram, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim) # embedding matrix of size |V|×d, where d is the size of embedding vectors\n",
    "        self.linear = nn.Linear(embedding_dim, vocab_size) # linear layer\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = self.linear(embeds)\n",
    "        log_probs = F.log_softmax(out, dim=1) # apply log softmax over each column ==> vec of size 1×|V|\n",
    "        return log_probs\n",
    "    \n",
    "    \n",
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim) \n",
    "        self.linear1 = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = torch.mean(self.embeddings(inputs), dim=0).view(1, -1) # take the mean of vectors of context words (over all rows) ==> vec of size 1×d\n",
    "        out = self.linear1(embeds)\n",
    "        log_probs = F.log_softmax(out, dim=1) \n",
    "        return log_probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an example embedding of ' our ' trained with Skip-gram:  tensor([-7.1349e-01,  1.4296e+00, -4.0149e-01,  1.7090e+00, -1.1879e+00,\n",
      "         3.7916e-01,  5.2712e-02, -3.2363e-01, -1.0842e+00, -1.0189e+00,\n",
      "         1.1449e-01,  9.8969e-01,  1.5166e-03,  3.5434e-02,  1.2757e+00,\n",
      "        -1.7873e+00,  1.4140e+00, -1.3263e+00,  1.0141e+00, -1.5681e+00,\n",
      "        -5.1523e-01, -1.1264e+00,  1.9136e+00,  1.9841e-01,  5.6155e-02,\n",
      "        -1.3283e-02,  9.9777e-01, -4.9598e-01,  8.0531e-01, -1.8616e+00,\n",
      "        -7.6723e-01,  1.6134e+00, -1.4284e+00,  3.0089e+00,  6.0521e-01,\n",
      "         9.7906e-01,  2.8048e+00,  1.5130e+00, -3.7982e-01, -5.9734e-01,\n",
      "         3.0410e-01,  9.4978e-01, -3.2633e-02,  3.3832e-01, -3.8687e-01,\n",
      "        -1.2456e+00, -1.4844e+00,  7.0881e-01, -1.1518e+00, -8.1747e-01])\n",
      "an example embedding of ' our ' trained with CBOW:  tensor([ 3.1244e-01,  5.8872e-01,  3.4466e-01,  3.9039e-01, -7.4655e-01,\n",
      "         6.2555e-01,  3.7278e-01,  9.9874e-01, -8.0956e-02, -3.1281e-01,\n",
      "        -2.0077e+00,  3.0214e-01, -1.0156e+00, -8.0440e-02, -1.5321e+00,\n",
      "         2.5702e+00, -9.3449e-02, -9.3781e-01, -4.7295e-01,  2.4508e-03,\n",
      "         4.3658e-01,  4.6100e-01,  1.0386e+00,  1.2370e+00,  1.7049e+00,\n",
      "         1.1546e+00,  6.7790e-01, -3.3844e-01,  4.8525e-01, -1.5775e-01,\n",
      "        -4.6891e-03, -6.7255e-01,  9.5522e-01,  2.7690e-01,  4.2624e-01,\n",
      "         1.8283e+00, -6.2190e-02, -3.3949e-01, -1.0047e+00, -5.4205e-01,\n",
      "        -1.6776e+00,  1.2117e+00,  5.3802e-01,  2.1564e+00,  1.0719e-01,\n",
      "        -8.5082e-02,  2.0616e+00, -5.7030e-01,  8.7642e-01, -5.3769e-01])\n",
      "SkipGram(\n",
      "  (embeddings): Embedding(46, 50)\n",
      "  (linear): Linear(in_features=50, out_features=46, bias=True)\n",
      ")\n",
      "CBOW(\n",
      "  (embeddings): Embedding(46, 50)\n",
      "  (linear1): Linear(in_features=50, out_features=46, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 20\n",
    "\n",
    "def train_skip_gram(data, weights):\n",
    "    losses = []\n",
    "    model = SkipGram(vocab_size, EMBEDDING_SIZE)\n",
    "    loss_fn = nn.NLLLoss(weight=weights)\n",
    "    #optimizer = optim.SGD(model.parameters(), LEARNING_RATE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), LEARNING_RATE)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0\n",
    "        for context, target in data:\n",
    "            context_var = Variable(torch.LongTensor(context))\n",
    "            target_var = Variable(torch.LongTensor([target]))\n",
    "\n",
    "            model.zero_grad()\n",
    "            log_probs = model(context_var)\n",
    "            loss = loss_fn(log_probs, target_var)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        losses.append(total_loss)\n",
    "        \n",
    "    # print an example embedding\n",
    "    word = list(freq_dict.keys())[0]\n",
    "    input = torch.autograd.Variable(torch.LongTensor([word_to_ix[word]]))\n",
    "    print(\"an example embedding of '\", word, \"' trained with Skip-gram: \", model.embeddings(input).data[0])\n",
    "    return model, losses\n",
    "\n",
    "\n",
    "def train_cbow(data, weights):\n",
    "    losses = []\n",
    "    model = CBOW(vocab_size, EMBEDDING_SIZE)\n",
    "    loss_fn = nn.NLLLoss(weight=weights)\n",
    "    #optimizer = optim.SGD(model.parameters(), LEARNING_RATE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), LEARNING_RATE)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0\n",
    "        for context, target in data:\n",
    "            context_var = Variable(torch.LongTensor(context))\n",
    "            target_var = Variable(torch.LongTensor([target]))\n",
    "            \n",
    "            model.zero_grad()\n",
    "            log_probs = model(context_var)\n",
    "            loss = loss_fn(log_probs, target_var)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        losses.append(total_loss)\n",
    "    \n",
    "    # print an example embedding\n",
    "    word = list(freq_dict.keys())[0]\n",
    "    input = torch.autograd.Variable(torch.LongTensor([word_to_ix[word]]))\n",
    "    print(\"an example embedding of '\", word, \"' trained with CBOW: \", model.embeddings(input).data[0])\n",
    "    return model, losses\n",
    "\n",
    "skip_gram_model, skip_gram_losses = train_skip_gram(data_skipgram, weights)\n",
    "cbow_model, cbow_losses = train_cbow(data_cbow, weights)\n",
    "print(skip_gram_model)\n",
    "print(cbow_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEZCAYAAABiu9n+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nV4uCxyUwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd674828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEZCAYAAABiu9n+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrZwkzMysVv8fDKr2gGN3lWoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd41f908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd60e278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss_fn(losses, title):\n",
    "    plt.plot(range(len(losses)), losses)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(title)\n",
    "    plt.figure()\n",
    "\n",
    "plot_loss_fn(skip_gram_losses, \"Skip-gram loss function\")\n",
    "plot_loss_fn(cbow_losses, \"CBOW loss function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing (only on training data, which is due to the small size of raw data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(test_data, model):\n",
    "    correct_counter = 0\n",
    "    for context, target in test_data:\n",
    "        context_var = Variable(torch.LongTensor(context))\n",
    "\n",
    "        model.zero_grad()\n",
    "        log_probs = model(context_var)\n",
    "        _, predicted = torch.max(log_probs.data, 1)\n",
    "        predicted_word = ix_to_word[predicted[0].item()]\n",
    "        print('predicted:', predicted_word)\n",
    "        print('label    :', ix_to_word[target])\n",
    "        if predicted_word == ix_to_word[target]:\n",
    "            correct_counter += 1\n",
    "\n",
    "    print('Accuracy: {:.1f}% ({:d}/{:d})'.format(correct_counter/len(test_data)*100, correct_counter, len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: to\n",
      "label    : to\n",
      "predicted: to\n",
      "label    : the\n",
      "predicted: are\n",
      "label    : are\n",
      "predicted: are\n",
      "label    : the\n",
      "predicted: are\n",
      "label    : of\n",
      "predicted: of\n",
      "label    : to\n",
      "predicted: of\n",
      "label    : are\n",
      "predicted: of\n",
      "label    : of\n",
      "predicted: of\n",
      "label    : computational\n",
      "predicted: the\n",
      "label    : the\n",
      "predicted: the\n",
      "label    : to\n",
      "predicted: the\n",
      "label    : computational\n",
      "predicted: the\n",
      "label    : .\n",
      "predicted: .\n",
      "label    : of\n",
      "predicted: .\n",
      "label    : the\n",
      "predicted: .\n",
      "label    : .\n",
      "predicted: .\n",
      "label    : processes\n",
      "predicted: we\n",
      "label    : computational\n",
      "predicted: we\n",
      "label    : of\n",
      "predicted: we\n",
      "label    : processes\n",
      "predicted: we\n",
      "label    : abstract\n",
      "predicted: things\n",
      "label    : .\n",
      "predicted: things\n",
      "label    : computational\n",
      "predicted: things\n",
      "label    : abstract\n",
      "predicted: things\n",
      "label    : that\n",
      "predicted: that\n",
      "label    : processes\n",
      "predicted: that\n",
      "label    : .\n",
      "predicted: that\n",
      "label    : that\n",
      "predicted: that\n",
      "label    : computers\n",
      "predicted: as\n",
      "label    : abstract\n",
      "predicted: as\n",
      "label    : processes\n",
      "predicted: as\n",
      "label    : computers\n",
      "predicted: as\n",
      "label    : as\n",
      "predicted: evolve\n",
      "label    : that\n",
      "predicted: evolve\n",
      "label    : abstract\n",
      "predicted: evolve\n",
      "label    : as\n",
      "predicted: evolve\n",
      "label    : evolve\n",
      "predicted: computers\n",
      "label    : computers\n",
      "predicted: computers\n",
      "label    : that\n",
      "predicted: computers\n",
      "label    : evolve\n",
      "predicted: computers\n",
      "label    : processes\n",
      "predicted: processes\n",
      "label    : as\n",
      "predicted: processes\n",
      "label    : computers\n",
      "predicted: processes\n",
      "label    : processes\n",
      "predicted: processes\n",
      "label    : other\n",
      "predicted: things\n",
      "label    : evolve\n",
      "predicted: things\n",
      "label    : as\n",
      "predicted: things\n",
      "label    : other\n",
      "predicted: things\n",
      "label    : things\n",
      "predicted: things\n",
      "label    : processes\n",
      "predicted: things\n",
      "label    : evolve\n",
      "predicted: things\n",
      "label    : things\n",
      "predicted: things\n",
      "label    : data\n",
      "predicted: data\n",
      "label    : other\n",
      "predicted: data\n",
      "label    : processes\n",
      "predicted: data\n",
      "label    : data\n",
      "predicted: data\n",
      "label    : the\n",
      "predicted: the\n",
      "label    : things\n",
      "predicted: the\n",
      "label    : other\n",
      "predicted: the\n",
      "label    : the\n",
      "predicted: the\n",
      "label    : of\n",
      "predicted: of\n",
      "label    : data\n",
      "predicted: of\n",
      "label    : things\n",
      "predicted: of\n",
      "label    : of\n",
      "predicted: of\n",
      "label    : process\n",
      "predicted: the\n",
      "label    : the\n",
      "predicted: the\n",
      "label    : data\n",
      "predicted: the\n",
      "label    : process\n",
      "predicted: the\n",
      "label    : directed\n",
      "predicted: of\n",
      "label    : of\n",
      "predicted: of\n",
      "label    : the\n",
      "predicted: of\n",
      "label    : directed\n",
      "predicted: of\n",
      "label    : a\n",
      "predicted: of\n",
      "label    : process\n",
      "predicted: of\n",
      "label    : of\n",
      "predicted: of\n",
      "label    : a\n",
      "predicted: of\n",
      "label    : of\n",
      "predicted: called\n",
      "label    : directed\n",
      "predicted: called\n",
      "label    : process\n",
      "predicted: called\n",
      "label    : of\n",
      "predicted: called\n",
      "label    : called\n",
      "predicted: the\n",
      "label    : a\n",
      "predicted: the\n",
      "label    : directed\n",
      "predicted: the\n",
      "label    : called\n",
      "predicted: the\n",
      "label    : program\n",
      "predicted: of\n",
      "label    : of\n",
      "predicted: of\n",
      "label    : a\n",
      "predicted: of\n",
      "label    : program\n",
      "predicted: of\n",
      "label    : people\n",
      "predicted: of\n",
      "label    : called\n",
      "predicted: of\n",
      "label    : of\n",
      "predicted: of\n",
      "label    : people\n",
      "predicted: of\n",
      "label    : programs\n",
      "predicted: programs\n",
      "label    : program\n",
      "predicted: programs\n",
      "label    : called\n",
      "predicted: programs\n",
      "label    : programs\n",
      "predicted: programs\n",
      "label    : direct\n",
      "predicted: people\n",
      "label    : people\n",
      "predicted: people\n",
      "label    : program\n",
      "predicted: people\n",
      "label    : direct\n",
      "predicted: people\n",
      "label    : .\n",
      "predicted: effect\n",
      "label    : programs\n",
      "predicted: effect\n",
      "label    : people\n",
      "predicted: effect\n",
      "label    : .\n",
      "predicted: effect\n",
      "label    : effect\n",
      "predicted: we\n",
      "label    : direct\n",
      "predicted: we\n",
      "label    : programs\n",
      "predicted: we\n",
      "label    : effect\n",
      "predicted: we\n",
      "label    : we\n",
      "predicted: the\n",
      "label    : .\n",
      "predicted: the\n",
      "label    : direct\n",
      "predicted: the\n",
      "label    : we\n",
      "predicted: the\n",
      "label    : the\n",
      "predicted: .\n",
      "label    : effect\n",
      "predicted: .\n",
      "label    : .\n",
      "predicted: .\n",
      "label    : the\n",
      "predicted: .\n",
      "label    : of\n",
      "predicted: of\n",
      "label    : we\n",
      "predicted: of\n",
      "label    : effect\n",
      "predicted: of\n",
      "label    : of\n",
      "predicted: of\n",
      "label    : computer\n",
      "predicted: the\n",
      "label    : the\n",
      "predicted: the\n",
      "label    : we\n",
      "predicted: the\n",
      "label    : computer\n",
      "predicted: the\n",
      "label    : our\n",
      "predicted: of\n",
      "label    : of\n",
      "predicted: of\n",
      "label    : the\n",
      "predicted: of\n",
      "label    : our\n",
      "predicted: of\n",
      "label    : .\n",
      "predicted: of\n",
      "label    : computer\n",
      "predicted: of\n",
      "label    : of\n",
      "predicted: of\n",
      "label    : .\n",
      "predicted: we\n",
      "label    : our\n",
      "predicted: we\n",
      "label    : computer\n",
      "Accuracy: 23.9% (32/134)\n",
      "predicted: are\n",
      "label    : are\n",
      "predicted: to\n",
      "label    : to\n",
      "predicted: the\n",
      "label    : the\n",
      "predicted: of\n",
      "label    : of\n",
      "predicted: computational\n",
      "label    : computational\n",
      "predicted: .\n",
      "label    : .\n",
      "predicted: processes\n",
      "label    : processes\n",
      "predicted: abstract\n",
      "label    : abstract\n",
      "predicted: that\n",
      "label    : that\n",
      "predicted: processes\n",
      "label    : computers\n",
      "predicted: as\n",
      "label    : as\n",
      "predicted: evolve\n",
      "label    : evolve\n",
      "predicted: processes\n",
      "label    : processes\n",
      "predicted: other\n",
      "label    : other\n",
      "predicted: things\n",
      "label    : things\n",
      "predicted: data\n",
      "label    : data\n",
      "predicted: the\n",
      "label    : the\n",
      "predicted: of\n",
      "label    : of\n",
      "predicted: process\n",
      "label    : process\n",
      "predicted: the\n",
      "label    : directed\n",
      "predicted: a\n",
      "label    : a\n",
      "predicted: of\n",
      "label    : of\n",
      "predicted: called\n",
      "label    : called\n",
      "predicted: program\n",
      "label    : program\n",
      "predicted: people\n",
      "label    : people\n",
      "predicted: programs\n",
      "label    : programs\n",
      "predicted: direct\n",
      "label    : direct\n",
      "predicted: .\n",
      "label    : .\n",
      "predicted: effect\n",
      "label    : effect\n",
      "predicted: we\n",
      "label    : we\n",
      "predicted: the\n",
      "label    : the\n",
      "predicted: of\n",
      "label    : of\n",
      "predicted: of\n",
      "label    : computer\n",
      "predicted: our\n",
      "label    : our\n",
      "predicted: .\n",
      "label    : .\n",
      "Accuracy: 91.4% (32/35)\n"
     ]
    }
   ],
   "source": [
    "test_model(data_skipgram, skip_gram_model)\n",
    "test_model(data_cbow, cbow_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## References\n",
    "# [1] Mikolov et al.: Distributed representations of words and phrases and their compositionality\n",
    "# Mikolov et al.: Efficient estimation of word representations in vector space\n",
    "# Jurafsky & Martin: Speech and Language Processing, Chapter 6\n",
    "# https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html#sphx-glr-beginner-nlp-word-embeddings-tutorial-py\n",
    "# https://github.com/dthiagarajan/word2vec-pytorch\n",
    "# https://github.com/jojonki/word2vec-pytorch"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
