# word2vec-pytorch
Implementation of the word2vec algorithms (Skip-gram and CBOW, both with subsampling and negative sampling) in PyTorch. The purpose of this project is to aid my understanding of word2vec, hence the verbosity of comments in the code.

## References
- [Mikolov et al.: Distributed representations of words and phrases and their compositionality](https://arxiv.org/pdf/1310.4546.pdf)
- [Mikolov et al.: Efficient estimation of word representations in vector space](https://arxiv.org/pdf/1301.3781.pdf)
- [Jurafsky & Martin: Speech and Language Processing, Chapter 6](https://web.stanford.edu/~jurafsky/slp3/6.pdf)
- [dthiagarajan's implementation](https://github.com/dthiagarajan/word2vec-pytorch)
- [jojonki's implementation](https://github.com/jojonki/word2vec-pytorch)
